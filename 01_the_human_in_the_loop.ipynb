{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce276647-5bc5-4cbb-aa9d-a4a13f53373c",
   "metadata": {},
   "source": [
    "# The Human in the Loop\n",
    "\n",
    "In the previous chapter, we perfected our knowledge of the standard supervised learning workflows. In this chapter, we will critically examine the ways in which expert knowledge is incorporated in supervised learning. This is done through the identification of the appropriate unit of analysis which might require feature engineering across multiple data sources, through the sometimes imperfect process of labeling examples, and through the specification of a loss function that captures the true business value of errors made by our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4f7bba5-6cc6-4beb-ba76-fb09c5115783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f74c43-fcc6-4b11-b20d-03f0883b98c4",
   "metadata": {},
   "source": [
    "## Data fusion\n",
    "\n",
    "Originaly, we used the _destination_ computer (from the `attack` dataset) as our entity of interest, and search for the  _destination_ in the `flow` dataset. However, our cybersecurity analyst just told us that it is the infected machines that generate the bad traffic, and will therefore appear as a _source_, not a _destination_, in the `flows` dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416ef877-81e0-4c27-befd-407a05729d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    return {\n",
    "        'unique_ports': len(set(df['destination_port'])),\n",
    "        'average_packet': np.mean(df['packet_count']),\n",
    "        'average_duration': np.mean(df['duration'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00fcce4-e1f5-4a4b-8d64-24a5badd79b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_domain</th>\n",
       "      <th>source_computer</th>\n",
       "      <th>destination_computer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151036</td>\n",
       "      <td>U748@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151648</td>\n",
       "      <td>U748@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151993</td>\n",
       "      <td>U6115@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153792</td>\n",
       "      <td>U636@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155219</td>\n",
       "      <td>U748@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C5693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time user_domain source_computer destination_computer\n",
       "0  151036   U748@DOM1          C17693                 C305\n",
       "1  151648   U748@DOM1          C17693                 C728\n",
       "2  151993  U6115@DOM1          C17693                C1173\n",
       "3  153792   U636@DOM1          C17693                 C294\n",
       "4  155219   U748@DOM1          C17693                C5693"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>source_computer</th>\n",
       "      <th>source_port</th>\n",
       "      <th>destination_computer</th>\n",
       "      <th>destination_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>packet_count</th>\n",
       "      <th>byte_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24128</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N17023</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N2414</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N19148</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24156</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N8001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24161</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N18502</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>471692</td>\n",
       "      <td>0</td>\n",
       "      <td>C5808</td>\n",
       "      <td>N24162</td>\n",
       "      <td>C26871</td>\n",
       "      <td>N11309</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  duration source_computer source_port destination_computer  \\\n",
       "0  471692         0           C5808      N24128               C26871   \n",
       "1  471692         0           C5808       N2414               C26871   \n",
       "2  471692         0           C5808      N24156               C26871   \n",
       "3  471692         0           C5808      N24161               C26871   \n",
       "4  471692         0           C5808      N24162               C26871   \n",
       "\n",
       "  destination_port  protocol  packet_count  byte_count  \n",
       "0           N17023         6             1          60  \n",
       "1           N19148         6             1          60  \n",
       "2            N8001         6             1          60  \n",
       "3           N18502         6             1          60  \n",
       "4           N11309         6             1          60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n"
     ]
    }
   ],
   "source": [
    "attack = pd.read_csv('data/redteam.csv')\n",
    "display(attack.head())\n",
    "print(\"#\"*40)\n",
    "\n",
    "flows = pd.read_csv('data/lanl_flows.csv')\n",
    "display(flows.head())\n",
    "print(\"#\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a35077c-cf4e-4370-976f-8ebe4a2f4689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445378151260504\n"
     ]
    }
   ],
   "source": [
    "bads = attack.destination_computer.values\n",
    "\n",
    "# Group by source computer, and apply the feature extractor\n",
    "out = flows.groupby('source_computer').apply(featurize)\n",
    "\n",
    "# Convert the iterator to a dataframe by calling list on it\n",
    "X = pd.DataFrame(list(out), index=out.index)\n",
    "\n",
    "# Check which sources in X.index are bad to create labels\n",
    "y = [x in bads for x in X.index]\n",
    "\n",
    "# Report the average accuracy of Adaboost over 3-fold CV\n",
    "print(np.mean(cross_val_score(AdaBoostClassifier(), X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f834fa-6103-42b7-bd6a-0bdc7ee6c38c",
   "metadata": {},
   "source": [
    "We have successfully incorporated our analyst's feedback. Let's now try to add some more features. \n",
    "\n",
    "We will now build on the previous exercise, by considering one additional feature: the number of unique protocols used by each source computer. Note that with grouped data, it is always possible to construct features in this manner: we can take the number of unique elements of all categorical columns, and the mean of all numeric columns as our starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f4140e-ac24-43fb-9412-60b9f1d80e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495798319327731\n"
     ]
    }
   ],
   "source": [
    "# Create a feature counting unique protocols per source\n",
    "protocols = flows.groupby('source_computer').apply(lambda df: len(set(df['protocol'])))\n",
    "\n",
    "# Convert this feature into a dataframe, naming the column\n",
    "protocols_DF = pd.DataFrame(protocols, index=protocols.index, columns=['protocol'])\n",
    "\n",
    "# Now concatenate this feature with the previous dataset, X\n",
    "X_more = pd.concat([X, protocols_DF], axis=1)\n",
    "\n",
    "# Refit the classifier and report its accuracy\n",
    "print(np.mean(cross_val_score(AdaBoostClassifier(), X_more, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2036b72-7e7a-43cc-830c-af3679782c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ports</th>\n",
       "      <th>average_packet</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>protocol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_computer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>4</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10026</th>\n",
       "      <td>2</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10047</th>\n",
       "      <td>5</td>\n",
       "      <td>21.076923</td>\n",
       "      <td>7.538462</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1015</th>\n",
       "      <td>35</td>\n",
       "      <td>5.371429</td>\n",
       "      <td>27.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10235</th>\n",
       "      <td>1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9873</th>\n",
       "      <td>2</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C993</th>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9937</th>\n",
       "      <td>4</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9941</th>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C997</th>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 unique_ports  average_packet  average_duration  protocol\n",
       "source_computer                                                          \n",
       "C10                         4      222.000000          5.000000         1\n",
       "C10026                      2       21.000000         39.000000         1\n",
       "C10047                      5       21.076923          7.538462         2\n",
       "C1015                      35        5.371429         27.571429         1\n",
       "C10235                      1       11.000000          0.000000         1\n",
       "...                       ...             ...               ...       ...\n",
       "C9873                       2       17.000000          4.500000         1\n",
       "C993                        1        5.000000          0.000000         1\n",
       "C9937                       4        7.166667          6.000000         2\n",
       "C9941                       1        3.000000         45.000000         1\n",
       "C997                        1       12.000000         11.000000         1\n",
       "\n",
       "[595 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40941c43-0166-4392-a127-8cf4bc57c5aa",
   "metadata": {},
   "source": [
    "We just achieved a further improvement by adding the number of unique protocols used by each source as a feature. \n",
    "\n",
    "## Labels, weak labels and truth\n",
    "\n",
    "We are surprised by the fact that heuristics can be so helpful. So we decide to treat the heuristic that \"too many unique ports is suspicious\" as a classifier in its own right. We achieve that by thresholding the number of unique ports per source by the average number used in bad source computers -- these are computers for which the label is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf2a19b-fcb5-47eb-a794-1b4249d447ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of unique ports visited by each infected host: 15.911764705882353.\n",
      "Average of unique ports visited per host disregarding labels: 11.235294117647058.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of unique ports visited by each infected host: {}.\".format(np.mean(X[y]['unique_ports'])))\n",
    "print(\"Average of unique ports visited per host disregarding labels: {}.\".format(np.mean(X['unique_ports'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd255f1c-361b-4f6e-ab63-4f22af9f3070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7495798319327731"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "446/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79b4c7b-a6de-4e71-9315-d9cc8352fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194630872483222\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test, with 25% as test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a new dataset X_train_bad by subselecting bad hosts\n",
    "X_train_bad = X_train[y_train]\n",
    "\n",
    "# Calculate the average of unique_ports in bad examples\n",
    "avg_bad_ports = np.mean(X_train_bad['unique_ports'])\n",
    "\n",
    "# Label as positive sources that use more ports than that\n",
    "pred_port = X_test['unique_ports'] > avg_bad_ports\n",
    "\n",
    "# Print the accuracy of the heuristic\n",
    "print(accuracy_score(y_test, pred_port))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61686be9-49ec-4a7f-96f9-423d8a9d98d0",
   "metadata": {},
   "source": [
    "Isn't it surprising how well a simple heuristic can do on a real problem? Let's see if we can find more such simple rules.\n",
    "\n",
    "A different cyber analyst tells us that during certain types of attack, the infected source computer sends small bits of traffic, to avoid detection. This makes us wonder whether it would be better to create a combined heuristic that simultaneously looks for large numbers of ports and small packet sizes. Does this improve performance over the simple port heuristic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5e9ef1-66af-42dd-9623-7f271900a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9328859060402684\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean of average_packet for bad sources\n",
    "avg_bad_packet = np.mean(X_train[y_train]['average_packet'])\n",
    "\n",
    "# Label as positive if average_packet is lower than that\n",
    "pred_packet = X_test['average_packet'] < avg_bad_packet\n",
    "\n",
    "# Find indices where pred_port and pred_packet both True\n",
    "pred_port = X_test['unique_ports'] > avg_bad_ports\n",
    "pred_both = pred_packet * pred_port\n",
    "\n",
    "# Ports only produced an accuracy of 0.919. Is this better?\n",
    "print(accuracy_score(y_test, pred_both))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25064f3d-bcc0-48bd-89f0-bffd904018d4",
   "metadata": {},
   "source": [
    "The combined rule does pretty well! Often expert knowledge comes in the form of logical combinations of a large number of simple heuristics.\n",
    "\n",
    "One of our cyber analysts informs you that many of the labels for the first 100 source computers in םור training data might be wrong because of a database error. She hopes we can still use the data because most of the labels are still correct, but asks וד to treat these 100 labels as \"noisy\". Thankfully we know how to do that, using weighted learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b355812-8008-4c3d-b131-06b88fcd3a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194630872483222\n",
      "0.8993288590604027\n"
     ]
    }
   ],
   "source": [
    "y_train_noisy = y_train\n",
    "# Fit a Gaussian Naive Bayes classifier to the training data\n",
    "clf = GaussianNB().fit(X_train, y_train_noisy)\n",
    "\n",
    "# Report its accuracy on the test data\n",
    "print(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "# Assign half the weight to the first 100 noisy examples\n",
    "weights = [0.5]*100 + [1.0]*(len(y_train_noisy)-100)\n",
    "\n",
    "# Refit using weights and report accuracy. Has it improved?\n",
    "clf_weights = GaussianNB().fit(X_train, y_train_noisy, sample_weight=weights)\n",
    "print(accuracy_score(y_test, clf_weights.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8bdb0-6cfd-4228-80c4-56306c72e6ce",
   "metadata": {},
   "source": [
    "We now have a way to handle noise in labels, by using weights that reflect our prior beliefs about their accuracy.\n",
    "\n",
    "## Loss functions Part I\n",
    "\n",
    "Remember the credit dataset? With all the extra knowledge you now have about metrics, let's have another look at how good a random forest is on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc678513-c752-417f-b85f-970a40683379",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('data/credit.csv')\n",
    "\n",
    "non_numeric_columns =   ['checking_status',\n",
    "                         'credit_history',\n",
    "                         'purpose',\n",
    "                         'savings_status',\n",
    "                         'employment',\n",
    "                         'personal_status',\n",
    "                         'other_parties',\n",
    "                         'property_magnitude',\n",
    "                         'other_payment_plans',\n",
    "                         'housing',\n",
    "                         'job',\n",
    "                         'own_telephone',\n",
    "                         'foreign_worker']\n",
    "\n",
    "# Create a label encoder for each column. Encode the values\n",
    "for column in non_numeric_columns:\n",
    "    le = LabelEncoder()\n",
    "    credit[column] = le.fit_transform(credit[column])\n",
    "\n",
    "credit['class'] = credit['class'] == 'bad'\n",
    "X, y = credit.drop('class', axis=1), credit['class']\n",
    "\n",
    "# Split the data into train and test, with 20% as test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create a random forest classifier, fixing the seed to 2\n",
    "rf_model = RandomForestClassifier(random_state=2).fit(X_train, y_train)\n",
    "\n",
    "# Use it to predict the labels of the test data\n",
    "preds = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b1111d-11b4-49f4-bf39-71839e01921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5161290322580646\n",
      "0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, preds))\n",
    "\n",
    "print(precision_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac05906-97c1-418f-b34e-e6e3bb4d9b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((preds == True) & (y_test == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f3b757e-6077-4f5c-893e-8b69f746a8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775\n"
     ]
    }
   ],
   "source": [
    "# Accuracy is the proportion of examples that were labelled correctly. Compute it without using accuracy_score()\n",
    "tp = sum((preds == True) & (y_test == True))\n",
    "tn = sum((preds == False) & (y_test == False))\n",
    "\n",
    "\n",
    "print((tp + tn)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba5063-1238-47cd-b63a-c42be96df0bc",
   "metadata": {},
   "source": [
    "We have mastered a number of performance metrics which will give us a lot of extra options when the time comes to build our own pipeline.\n",
    "\n",
    "We will still work on the credit dataset for this exercise. Recall that a \"positive\" in this dataset means \"bad credit\", i.e., a customer who defaulted on their loan, and a \"negative\" means a customer who continued to pay without problems. The bank manager informed us that the bank makes 10K profit on average from each \"good risk\" customer, but loses 150K from each \"bad risk\" customer. Our algorithm will be used to screen applicants, so those that are labeled as \"negative\" will be given a loan, and the \"positive\" ones will be turned down. What is the total cost of our classifier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dafe4c72-260b-4c26-9d48-8a5e1bc4cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5350\n"
     ]
    }
   ],
   "source": [
    "# Fit a random forest classifier to the training data\n",
    "clf = RandomForestClassifier(random_state=2).fit(X_train, y_train)\n",
    "\n",
    "# Label the test data\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "# Get false positives/negatives from the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# Now compute the cost using the manager's advice\n",
    "'''\n",
    "Falsely classifying a \"good\" customer as \"bad\" means that the bank would have lost the chance to make 10K profit. \n",
    "Falsely classifying a \"bad\" customer as \"good\" means that the bank would have lost 150K due to the customer defaulting on their loan.\n",
    "'''\n",
    "cost = fp*10 + fn*150\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6771e9d-a4ff-4796-94e3-7950c31b896d",
   "metadata": {},
   "source": [
    "This sort of analysis is the only way to assess what the actual impact of our classifier will be in the real world.\n",
    "\n",
    "## Loss functions Part II\n",
    "\n",
    "We would like to confirm that the `DecisionTreeClassifier()` uses the same default classification threshold as mentioned in the previous lesson, namely 0.5. It seems strange to us that all classifiers should use the same threshold. Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d27676a2-9e52-4d13-b83d-6d6c0c963aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the test data using the given classifier\n",
    "scores = clf.predict_proba(X_test)\n",
    "\n",
    "# Get labels from the scores using the default threshold\n",
    "preds = [s[1] > 0.5 for s in scores]\n",
    "\n",
    "# Use the predict method to label the test data again\n",
    "preds_default = clf.predict(X_test)\n",
    "\n",
    "# Compare the two sets of predictions\n",
    "all(preds == preds_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f624ad-d951-42e5-897f-bbd5c4673936",
   "metadata": {},
   "source": [
    "We have confirmed that this classifier, too, uses 0.5 as a threshold. We will later see how to tune that threshold to fit our purposes.\n",
    "\n",
    "We heard that the default value of 0.5 maximizes accuracy in theory, but we want to test what happens in practice. So we try out a number of different threshold values, to see what accuracy we get, and hence determine the best-performing threshold value. We repeat this experiment for the F1 score. Is 0.5 the optimal threshold? Is the optimal threshold for accuracy and for the F1 score the same? Go ahead and find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a383bb4-0209-464b-b940-4276c3c6aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.25\n"
     ]
    }
   ],
   "source": [
    "# Create a range of equally spaced threshold values\n",
    "t_range = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "# Store the predicted labels for each value of the threshold\n",
    "preds = [[s[1] > thr for s in scores] for thr in t_range]\n",
    "\n",
    "# Compute the accuracy for each threshold\n",
    "accuracies = [accuracy_score(y_test, p) for p in preds]\n",
    "\n",
    "# Compute the F1 score for each threshold\n",
    "f1_scores = [f1_score(y_test, p) for p in preds]\n",
    "\n",
    "# Report the optimal threshold for accuracy, and for F1\n",
    "print(t_range[np.argmax(accuracies)], t_range[np.argmax(f1_scores)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579cc89c-9270-475c-a94a-7cbd5f5baa9d",
   "metadata": {},
   "source": [
    "We were right to be suspicious: in practice, accuracy is sometimes optimized with a threshold other than 0.5. Moreover, if we want to use a different metric, we should re-tune our threshold!\n",
    "\n",
    "One of the engineers in our arrhythmia detection startup rushes into our office to let us know that there is a problem with the ECG sensor for overweight users. We decide to reduce the influence of examples with weight over 80 by 50%. We are also told that since our startup is targeting the fitness market and makes no medical claims, scaring an athlete unnecessarily is costlier than missing a possible case of arrhythmia. We decide to create a custom loss that makes each \"false alarm\" ten times costlier than missing a case of arrhythmia. Does down-weighting overweight subjects improve this custom loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3938da9-1b26-4671-96f3-f3c4df7f66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrh = pd.read_csv('data/arrh.csv')\n",
    "# arrh['class'] = arrh['class'] == 'bad'\n",
    "X, y = arrh.drop('class', axis=1), arrh['class']\n",
    "# Split the data into train and test, with 20% as test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b956a83-5c0b-406a-812a-11e8a111f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122.0\n"
     ]
    }
   ],
   "source": [
    "# Create a scorer assigning more cost to false positives\n",
    "def my_scorer(y_test, y_est, cost_fp=10.0, cost_fn=1.0):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_est).ravel()\n",
    "    return cost_fp*fp + cost_fn*fn\n",
    "\n",
    "# Fit a DecisionTreeClassifier to the data and compute the loss\n",
    "clf = DecisionTreeClassifier(random_state=2).fit(X_train, y_train)\n",
    "print(my_scorer(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8f7bcba-405d-4cf4-8a47-d2fc4873596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122.0\n",
      "161.0\n"
     ]
    }
   ],
   "source": [
    "# Create a scorer assigning more cost to false positives\n",
    "def my_scorer(y_test, y_est, cost_fp=10.0, cost_fn=1.0):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_est).ravel()\n",
    "    return cost_fp*fp + cost_fn*fn\n",
    "\n",
    "# Fit a DecisionTreeClassifier to the data and compute the loss\n",
    "clf = DecisionTreeClassifier(random_state=2).fit(X_train, y_train)\n",
    "print(my_scorer(y_test, clf.predict(X_test)))\n",
    "\n",
    "# Refit with same seed, downweighting subjects weighing > 80\n",
    "weights = [0.5 if w > 80 else 1.0 for w in X_train.weight]\n",
    "clf_weighted = DecisionTreeClassifier(random_state=2).fit(\n",
    "  X_train, y_train, sample_weight=weights)\n",
    "print(my_scorer(y_test, clf_weighted.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e2caee-faa1-4ed8-9363-f48e265a9398",
   "metadata": {},
   "source": [
    "We have mastered the art of using weights in order to assign different importance to different parts of the data. Time to revisit our optimization skills using pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf10e0-031b-42bc-bb27-0853330dd1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lingua",
   "language": "python",
   "name": "lingua"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
