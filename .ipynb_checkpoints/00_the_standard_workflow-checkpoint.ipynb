{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Standard Workflow\n",
    "\n",
    "In this chapter, we will be reminded of the basics of a supervised learning workflow, complete with model fitting, tuning and selection, feature engineering and selection, and data splitting techniques. We will understand how these steps in a workflow depend on each other, and recognize how they can all contribute to, or fight against overfitting: the data scientist's worst enemy. By the end of the chapter, we will already be fluent in supervised learning, and ready to take the dive towards more advanced material in later chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning pipelines\n",
    "\n",
    "We are tasked with predicting whether or not a new cohort of loan applicants are likely to default on their loans. We have a historical dataset and wish to train a classifier on it. We notice that many features are in string format, which is a problem for our classifiers. We hence decide to encode the string columns numerically using `LabelEncoder()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking_status           object\n",
      "duration                   int64\n",
      "credit_history            object\n",
      "purpose                   object\n",
      "credit_amount              int64\n",
      "savings_status            object\n",
      "employment                object\n",
      "installment_commitment     int64\n",
      "personal_status           object\n",
      "other_parties             object\n",
      "residence_since            int64\n",
      "property_magnitude        object\n",
      "age                        int64\n",
      "other_payment_plans       object\n",
      "housing                   object\n",
      "existing_credits           int64\n",
      "job                       object\n",
      "num_dependents             int64\n",
      "own_telephone             object\n",
      "foreign_worker            object\n",
      "class                     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>6</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>buy_radio_tv</td>\n",
       "      <td>1169</td>\n",
       "      <td>'no known savings'</td>\n",
       "      <td>'&gt;=7'</td>\n",
       "      <td>4</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>67</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'0&lt;=X&lt;200'</td>\n",
       "      <td>48</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>buy_radio_tv</td>\n",
       "      <td>5951</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>2</td>\n",
       "      <td>'female div/dep/mar'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>22</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'no checking'</td>\n",
       "      <td>12</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>education</td>\n",
       "      <td>2096</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>49</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>'unskilled resident'</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration                    credit_history       purpose  \\\n",
       "0            '<0'         6  'critical/other existing credit'  buy_radio_tv   \n",
       "1      '0<=X<200'        48                   'existing paid'  buy_radio_tv   \n",
       "2   'no checking'        12  'critical/other existing credit'     education   \n",
       "\n",
       "   credit_amount      savings_status employment  installment_commitment  \\\n",
       "0           1169  'no known savings'      '>=7'                       4   \n",
       "1           5951              '<100'   '1<=X<4'                       2   \n",
       "2           2096              '<100'   '4<=X<7'                       2   \n",
       "\n",
       "        personal_status other_parties  ...  property_magnitude age  \\\n",
       "0         'male single'          none  ...       'real estate'  67   \n",
       "1  'female div/dep/mar'          none  ...       'real estate'  22   \n",
       "2         'male single'          none  ...       'real estate'  49   \n",
       "\n",
       "   other_payment_plans housing existing_credits                   job  \\\n",
       "0                 none     own                2               skilled   \n",
       "1                 none     own                1               skilled   \n",
       "2                 none     own                1  'unskilled resident'   \n",
       "\n",
       "  num_dependents  own_telephone foreign_worker class  \n",
       "0              1            yes            yes  good  \n",
       "1              1           none            yes   bad  \n",
       "2              2           none            yes  good  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.read_csv('data/credit.csv')\n",
    "\n",
    "# Inspect the data types of the columns of the data frame\n",
    "print(credit.dtypes)\n",
    "# Inspect the first few lines of your data using head()\n",
    "credit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking_status            int32\n",
      "duration                   int64\n",
      "credit_history             int32\n",
      "purpose                    int32\n",
      "credit_amount              int64\n",
      "savings_status             int32\n",
      "employment                 int32\n",
      "installment_commitment     int64\n",
      "personal_status            int32\n",
      "other_parties              int32\n",
      "residence_since            int64\n",
      "property_magnitude         int32\n",
      "age                        int64\n",
      "other_payment_plans        int32\n",
      "housing                    int32\n",
      "existing_credits           int64\n",
      "job                        int32\n",
      "num_dependents             int64\n",
      "own_telephone              int32\n",
      "foreign_worker             int32\n",
      "class                     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "non_numeric_columns =   ['checking_status',\n",
    "                         'credit_history',\n",
    "                         'purpose',\n",
    "                         'savings_status',\n",
    "                         'employment',\n",
    "                         'personal_status',\n",
    "                         'other_parties',\n",
    "                         'property_magnitude',\n",
    "                         'other_payment_plans',\n",
    "                         'housing',\n",
    "                         'job',\n",
    "                         'own_telephone',\n",
    "                         'foreign_worker']\n",
    "\n",
    "# Create a label encoder for each column. Encode the values\n",
    "for column in non_numeric_columns:\n",
    "    le = LabelEncoder()\n",
    "    credit[column] = le.fit_transform(credit[column])\n",
    "\n",
    "# Inspect the data types of the columns of the data frame\n",
    "print(credit.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a fully numeric matrix we can now pretty much use any classifier you like! Let's try a couple out. \n",
    "\n",
    "Our colleague has used `AdaBoostClassifier` for the credit scoring dataset. We want to also try out a random forest classifier. In this exercise, we will fit this classifier to the data and compare it to `AdaBoostClassifier`.We will use train/test data splitting to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab': 0.75, 'rf': 0.775}\n"
     ]
    }
   ],
   "source": [
    "accuracies = {'ab': 0.75}\n",
    "\n",
    "X, y = credit.drop('class', axis=1), credit['class']\n",
    "\n",
    "# Split the data into train and test, with 20% as test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create a random forest classifier, fixing the seed to 2\n",
    "rf_model = RandomForestClassifier(random_state=2).fit(\n",
    "  X_train, y_train)\n",
    "\n",
    "# Use it to predict the labels of the test data\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Assess the accuracy of both classifiers\n",
    "accuracies['rf'] = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just built our first pipeline. Did you wonder whether there are any additional parameters that we could tune to make AdaBoost even better? The answer is yes! Let's explore that in our next lesson on tuning parameters.\n",
    "\n",
    "## Model complexity and overfitting\n",
    "\n",
    "Most classifiers have one or more hyperparameters that control its complexity. We can tune them using `GridSearchCV()`. In this exercise, we will perfect this skill. We will experiment with:\n",
    "\n",
    "- The number of trees, `n_estimators`, in a `RandomForestClassifier`.\n",
    "- The maximum depth, `max_depth`, of the decision trees used in an `AdaBoostClassifier`.\n",
    "- The number of nearest neighbors, `n_neighbors`, in `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 40}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a range for n_estimators from 10 to 40 in steps of 10\n",
    "param_grid = {'n_estimators': range(10, 50, 10)}\n",
    "\n",
    "# Optimize for a RandomForestClassifier() using GridSearchCV\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)\n",
    "grid.fit(X, y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a grid for n_estimators ranging from 1 to 10\n",
    "param_grid = {'n_estimators': range(1, 11)}\n",
    "\n",
    "# Optimize for a AdaBoostClassifier() using GridSearchCV\n",
    "grid = GridSearchCV(AdaBoostClassifier(), param_grid, cv=3)\n",
    "grid.fit(X, y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 50}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a grid for n_neighbors with values 10, 50 and 100\n",
    "param_grid = {'n_neighbors': [10, 50, 100]}\n",
    "\n",
    "# Optimize for KNeighborsClassifier() using GridSearchCV\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3)\n",
    "grid.fit(X, y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to deal with the extremely important issue of model complexity.\n",
    "\n",
    "## Feature engineering and overfitting\n",
    "\n",
    "Our colleague has converted the columns in the credit dataset to numeric values using `LabelEncoder()`. He left one out: `credit_history`, which records the credit history of the applicant. We want to create two versions of the dataset. One will use `LabelEncoder()` and another one-hot encoding, for comparison purposes. The feature matrix is available to you as credit. You have LabelEncoder() preloaded and pandas as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "credit = pd.read_csv('data/credit.csv')\n",
    "\n",
    "# Create numeric encoding for credit_history\n",
    "credit_history_num = LabelEncoder().fit_transform(credit['credit_history'])\n",
    "\n",
    "# Create a new feature matrix including the numeric encoding\n",
    "X_num = pd.concat([X, pd.Series(credit_history_num)], axis=1)\n",
    "\n",
    "# Create new feature matrix with dummies for credit_history\n",
    "X_hot = pd.concat([X, pd.get_dummies(credit['credit_history'])], axis=1)\n",
    "\n",
    "# Compare the number of features of the resulting DataFrames\n",
    "print(X_hot.shape[1] > X_num.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are discussing the credit dataset with the bank manager. She suggests that the safest loan applications tend to request mid-range credit amounts. Values that are either too low or too high suggest high risk. This means that a non-linear relationship might exist between this variable and the class. We want to test this hypothesis. We will construct a non-linear transformation of the feature. Then, we will assess which of the two features is better at predicting the class using `SelectKBest()` and the `chi2()` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function computing absolute difference from column mean\n",
    "def abs_diff(x):\n",
    "    return np.abs(x-np.mean(x))\n",
    "\n",
    "# Apply it to the credit amount and store to new column\n",
    "credit['diff'] = abs_diff(credit['credit_amount'])\n",
    "\n",
    "# Create a feature selector with chi2 that picks one feature\n",
    "sk = SelectKBest(chi2, k=1)\n",
    "\n",
    "# Use the selector to pick between credit_amount and diff\n",
    "sk.fit(credit[['diff','credit_amount']], credit['class'])\n",
    "\n",
    "# Inspect the results\n",
    "sk.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have one more tool at our disposal to decide which features are worth introducing to your dataset.\n",
    "\n",
    "We just joined an arrhythmia detection startup and want to train a model on the arrhythmias dataset `arrh`. We noticed that random forests tend to win quite a few Kaggle competitions, so we want to try that out with a maximum depth of 2, 5, or 10, using grid search. We also observe that the dimension of the dataset is quite high so we wish to consider the effect of a feature selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrh = pd.read_csv('data/arrh.csv')\n",
    "\n",
    "X, y = arrh.drop('class', axis=1), arrh['class']\n",
    "# Split the data into train and test, with 20% as test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Find the best value for max_depth among values 2, 5 and 10\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=1), param_grid={'max_depth': [2,5,10]})\n",
    "best_value = grid_search.fit(X_train, y_train).best_params_['max_depth']\n",
    "\n",
    "# Using the best value from above, fit a random forest\n",
    "clf = RandomForestClassifier(random_state=1, max_depth=best_value).fit(X_train, y_train)\n",
    "\n",
    "# Apply SelectKBest with chi2 and pick top 100 features\n",
    "vt = SelectKBest(chi2, k=100).fit(abs(X_train), y_train)\n",
    "\n",
    "# Create a new dataset only containing the selected features\n",
    "X_train_reduced = vt.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already able to handle hundreds of features in a few lines of code! But what if the optimal number of estimators is different if we first apply feature selection? In Chapter 3 we will learn how to put our pipelines on steroids so that such questions can be asked in just one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lingua",
   "language": "python",
   "name": "lingua"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
